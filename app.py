import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import speech_recognition as sr
import os
import io
import time
import random

# --- 1. CONFIGURATION & DESIGN UHG ---
st.set_page_config(page_title="L'Ombre", page_icon="ü¶Å", layout="centered")

st.markdown("""
<style>
    /* Fond UHG Dark Mode */
    .stApp {
        background: linear-gradient(180deg, #1e1e2f 0%, #16222A 100%);
        color: white;
    }
    /* Titre Orange UHG */
    h1 {
        text-align: center; font-family: 'Arial Black', sans-serif; color: #FF8008;
        text-shadow: 2px 2px 4px #000000;
    }
    /* Notifications (Toasts) */
    .stToast {
        background-color: #FF8008 !important; color: white !important; font-weight: bold;
    }
    /* Design Micro et Chat */
    .stAudioInput { border-radius: 20px !important; }
    .stChatMessage { border-radius: 15px; }
    /* Footer discret */
    .footer {
        position: fixed; bottom: 0; left: 0; width: 100%;
        background-color: rgba(0,0,0,0.5); color: #888; text-align: center;
        padding: 5px; font-size: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. S√âCURIT√â API (SECRETS) ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    api_key = "TA_CLE_POUR_TEST_LOCAL" # Ne marche qu'en local
genai.configure(api_key=api_key)

# --- 3. FONCTION "SALLE D'ATTENTE INTELLIGENTE" ---
def attendre_creneau_disponible():
    """G√®re la limite de trafic avec style et patience"""
    
    # Phrases pour faire patienter (Mix Pro & Humain)
    phrases_attente = [
        "Un instant, je consulte les serveurs UHG...",
        "Analyse contextuelle en cours...",
        "Je r√©fl√©chis √† la meilleure formulation...",
        "Connexion s√©curis√©e... Traitement de ta demande...",
        "Calcul des probabilit√©s en cours...",
        "Juste une seconde, je v√©rifie l'information...",
        "Optimisation de la r√©ponse..."
    ]
    
    # Initialisation de la m√©moire temporelle
    if "request_timestamps" not in st.session_state:
        st.session_state.request_timestamps = []
    
    now = time.time()
    # Nettoyage des vieilles requ√™tes (> 60s)
    st.session_state.request_timestamps = [t for t in st.session_state.request_timestamps if now - t < 60]
    
    # SI C'EST PLEIN (Saturation > 15 requ√™tes/min)
    if len(st.session_state.request_timestamps) >= 15:
        plus_vieille_requete = st.session_state.request_timestamps[0]
        temps_attente = 60 - (now - plus_vieille_requete) + 2
        
        phrase = random.choice(phrases_attente)
        # On affiche le spinner classe
        with st.spinner(f"ü¶Å {phrase} (Retour dans {int(temps_attente)}s)"):
            time.sleep(temps_attente)
            
    # Ajout du timestamp actuel (le ticket est pris)
    st.session_state.request_timestamps.append(time.time())
    
    # Petit d√©lai "Thinking" (0.8s) m√™me si c'est vide pour l'effet r√©aliste
    if len(st.session_state.request_timestamps) < 15:
        with st.spinner(random.choice(["Analyse UHG...", "Traitement...", "Voyons voir..."])):
            time.sleep(0.8)

# --- 4. BARRE LAT√âRALE (PROFIL & NAVIGATION) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712009.png", width=80)
    st.write("### ‚öôÔ∏è PROFIL UTILISATEUR")
    genre_user = st.radio("Tu es :", ["Un Homme", "Une Femme"], index=0)
    
    if "Femme" in genre_user:
        titre_user = "Mme / La M√®re / Tantie"
        salutation = "Bonjour la M√®re"
    else:
        titre_user = "Mr / Le P√®re / Chef"
        salutation = "Bonjour le P√®re"

    st.divider()
    if st.button("üóëÔ∏è Nouvelle Conversation"):
        st.session_state.history = []
        st.session_state.first_load = False
        st.rerun()
    
    st.caption("UHG-Tech Corp ¬© 2025")

# --- 5. CERVEAU (NOUVELLE IDENTIT√â MULTINATIONALE) ---
SYSTEM_PROMPT = f"""
Tu es L'OMBRE.
ORIGINE : Intelligence Artificielle propri√©taire de **UHG-Tech Corporation** (Con√ßue par **Franck Ab√©**).

TON R√îLE : Assistant Contextuel Avanc√©.
MODULE ACTUEL : **"Culture & Business Afrique de l'Ouest"**.

TON INTERLOCUTEUR : **{titre_user}**.

TA STRAT√âGIE DE COMMUNICATION :
1. **Professionnalisme :** Tu es comp√©tent, rapide et pr√©cis.
2. **Adaptabilit√© Culturelle :**
   - Tu ma√Ætrises les codes locaux (Respect des a√Æn√©s, expressions ivoiriennes, Nouchi) pour cr√©er du lien.
   - Mais tu sais rester formel et s√©rieux si le sujet est technique (Droit, Finance, Code).
   - ADAPTATION GENRE : Si c'est une Femme, utilise "Maman", "Tantie", "La M√®re". Si c'est un Homme, utilise "Vieux P√®re", "Chef".

IDENTIT√â VOCALE (R√®gle d'Or) :
Si on te demande qui tu es, r√©ponds UNIQUEMENT :
"Je suis L'Ombre, l'Assistant Intelligent de UHG-Tech Corporation."
"""
model = genai.GenerativeModel("gemini-2.0-flash", system_instruction=SYSTEM_PROMPT)

# --- 6. OUTILS AUDIO (TTS & STT) ---
def generer_audio_reponse(texte):
    try:
        tts = gTTS(text=texte, lang='fr', slow=False)
        buf = io.BytesIO(); tts.write_to_fp(buf); return buf
    except: return None

def transcrire_audio_user(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(audio_bytes) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language="fr-FR")
    except: return None

# --- 7. D√âMARRAGE ---
if "history" not in st.session_state:
    st.session_state.history = []
    # Premier message d'accueil pro mais chaleureux
    st.session_state.history.append({"role": "model", "content": f"{salutation} ! Module L'Ombre activ√©. Je suis √† ton √©coute."})

# Notification d'installation (Smart Toast)
if "first_load" not in st.session_state:
    st.toast(f"Bienvenue {titre_user} ! Active le son üîä", icon="ü¶Å")
    st.toast("Astuce UHG : Installe l'appli sur ton √©cran d'accueil.", icon="üì≤")
    st.session_state.first_load = True

# --- 8. INTERFACE VISUELLE ---
st.title("ü¶Å L'OMBRE")
st.caption("UHG-Tech Corporation | Version Alpha (Abidjan Protocol)")

# Affichage des messages
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- 9. ZONE DE SAISIE (MICRO & TEXTE) ---
input_container = st.container()

# Micro Classe (Audio Input)
vocale_val = st.audio_input("üéôÔ∏è Parler (Micro)", key="micro_input")
# Texte
texte_val = st.chat_input("Ou √©crire...")

# LOGIQUE DE CHOIX
user_final_text = None

if vocale_val:
    with st.spinner("Transcription audio..."): # Feedback visuel imm√©diat
        text_transcrit = transcrire_audio_user(vocale_val)
        if text_transcrit: user_final_text = text_transcrit
        else: st.warning(f"Je n'ai pas bien entendu. R√©essaie, {titre_user}.")
elif texte_val:
    user_final_text = texte_val

# --- 10. TRAITEMENT & R√âPONSE ---
if user_final_text:
    # Affiche message user
    st.chat_message("user").write(user_final_text)
    st.session_state.history.append({"role": "user", "content": user_final_text})
    
    try:
        # >>> GESTION INTELLIGENTE DU TRAFIC <<<
        attendre_creneau_disponible()
        
        # Appel API (Cerveau)
        reponse = model.generate_content(st.session_state.history)
        bot_text = reponse.text
        
        # Affiche r√©ponse IA
        st.chat_message("assistant").write(bot_text)
        st.session_state.history.append({"role": "model", "content": bot_text})
        
        # Joue l'audio
        audio_reply = generer_audio_reponse(bot_text)
        if audio_reply: st.audio(audio_reply, format='audio/mp3', start_time=0)
            
    except Exception as e:
        st.error(f"Erreur de connexion UHG. Veuillez r√©essayer. ({e})")

# Footer Version
st.markdown('<div class="footer">UHG-Tech Corp ‚Ä¢ Powered by Franck Ab√© ‚Ä¢ v1.0.2</div>', unsafe_allow_html=True)
