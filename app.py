import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import speech_recognition as sr
import os
import io
import time
import random

# --- 1. CONFIGURATION & DESIGN UHG ---
st.set_page_config(page_title="L'Ombre", page_icon="ü¶Å", layout="centered")

st.markdown("""
<style>
    /* Fond UHG Dark Mode */
    .stApp {
        background: linear-gradient(180deg, #1e1e2f 0%, #16222A 100%);
        color: white;
    }
    /* Titre Orange UHG */
    h1 {
        text-align: center; font-family: 'Arial Black', sans-serif; color: #FF8008;
        text-shadow: 2px 2px 4px #000000;
    }
    /* Notifications (Toasts) */
    .stToast {
        background-color: #FF8008 !important; color: white !important; font-weight: bold;
    }
    /* Design Micro et Chat */
    .stAudioInput { border-radius: 20px !important; }
    .stChatMessage { border-radius: 15px; }
    /* Footer discret */
    .footer {
        position: fixed; bottom: 0; left: 0; width: 100%;
        background-color: rgba(0,0,0,0.5); color: #888; text-align: center;
        padding: 5px; font-size: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. S√âCURIT√â API (SECRETS) ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    # Fallback pour √©viter le crash si la cl√© manque, mais l'appli ne r√©pondra pas
    api_key = None 

if api_key:
    genai.configure(api_key=api_key)

# --- 3. FONCTION "SALLE D'ATTENTE INTELLIGENTE" ---
def attendre_creneau_disponible():
    """G√®re la limite de trafic avec style et patience"""
    phrases_attente = [
        "Un instant, je consulte les serveurs UHG...",
        "Analyse contextuelle en cours...",
        "Je r√©fl√©chis √† la meilleure formulation...",
        "Connexion s√©curis√©e... Traitement de ta demande...",
        "Calcul des probabilit√©s en cours...",
        "Juste une seconde, je v√©rifie l'information...",
        "Optimisation de la r√©ponse..."
    ]
    
    if "request_timestamps" not in st.session_state:
        st.session_state.request_timestamps = []
    
    now = time.time()
    # Nettoyage des vieilles requ√™tes (> 60s)
    st.session_state.request_timestamps = [t for t in st.session_state.request_timestamps if now - t < 60]
    
    # SI C'EST PLEIN (Saturation > 15 requ√™tes/min)
    if len(st.session_state.request_timestamps) >= 15:
        plus_vieille_requete = st.session_state.request_timestamps[0]
        temps_attente = 60 - (now - plus_vieille_requete) + 2
        
        phrase = random.choice(phrases_attente)
        with st.spinner(f"ü¶Å {phrase} (Retour dans {int(temps_attente)}s)"):
            time.sleep(temps_attente)
            
    # Ajout du timestamp actuel
    st.session_state.request_timestamps.append(time.time())
    
    if len(st.session_state.request_timestamps) < 15:
        with st.spinner(random.choice(["Analyse UHG...", "Traitement...", "Voyons voir..."])):
            time.sleep(0.5)

# --- 4. BARRE LAT√âRALE ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712009.png", width=80)
    st.write("### ‚öôÔ∏è PROFIL UTILISATEUR")
    genre_user = st.radio("Tu es :", ["Un Homme", "Une Femme"], index=0)
    
    if "Femme" in genre_user:
        titre_user = "Mme / La M√®re / Tantie"
        salutation = "Bonjour la M√®re"
    else:
        titre_user = "Mr / Le P√®re / Chef"
        salutation = "Bonjour le P√®re"

    st.divider()
    if st.button("üóëÔ∏è Nouvelle Conversation"):
        st.session_state.history = []
        st.session_state.first_load = False
        st.rerun()
    
    st.caption("UHG-Tech Corp ¬© 2025")

# --- 5. CERVEAU (CONFIG PRO) ---
SYSTEM_PROMPT = f"""
Tu es L'OMBRE.
ORIGINE : Intelligence Artificielle propri√©taire de **UHG-Tech Corporation** (Con√ßue par **Franck Ab√©**).

TON R√îLE : Assistant Contextuel Avanc√©.
MODULE ACTUEL : **"Culture & Business Afrique de l'Ouest"**.

TON INTERLOCUTEUR : **{titre_user}**.

TA STRAT√âGIE DE COMMUNICATION :
1. **Professionnalisme :** Tu es comp√©tent, rapide et pr√©cis.
2. **Adaptabilit√© Culturelle :**
   - Tu ma√Ætrises les codes locaux (Respect des a√Æn√©s, expressions ivoiriennes, Nouchi) pour cr√©er du lien.
   - Mais tu sais rester formel et s√©rieux si le sujet est technique (Droit, Finance, Code).
   - ADAPTATION GENRE : Si c'est une Femme, utilise "Maman", "Tantie", "La M√®re". Si c'est un Homme, utilise "Vieux P√®re", "Chef".

IDENTIT√â VOCALE :
Si on te demande qui tu es, r√©ponds UNIQUEMENT :
"Je suis L'Ombre, l'Assistant Intelligent de UHG-Tech Corporation."
"""
model = genai.GenerativeModel("gemini-2.0-flash", system_instruction=SYSTEM_PROMPT)

# --- 6. OUTILS AUDIO ---
def generer_audio_reponse(texte):
    try:
        tts = gTTS(text=texte, lang='fr', slow=False)
        buf = io.BytesIO(); tts.write_to_fp(buf); return buf
    except: return None

def transcrire_audio_user(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(audio_bytes) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language="fr-FR")
    except: return None

# --- 7. D√âMARRAGE ---
if "history" not in st.session_state:
    st.session_state.history = []
    # Note : On n'ajoute pas le message d'accueil dans l'historique API pour √©viter les bugs de format
    # On l'affiche juste visuellement si l'historique est vide
    st.chat_message("assistant").write(f"{salutation} ! Module L'Ombre activ√©. Je suis √† ton √©coute.")

if "first_load" not in st.session_state:
    st.toast(f"Bienvenue {titre_user} ! Active le son üîä", icon="ü¶Å")
    st.toast("Astuce UHG : Installe l'appli sur ton √©cran d'accueil.", icon="üì≤")
    st.session_state.first_load = True

# --- 8. INTERFACE VISUELLE ---
st.title("ü¶Å L'OMBRE")
st.caption("UHG-Tech Corporation | Version Alpha (Abidjan Protocol)")

# Affichage de l'historique visuel
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- 9. ZONE DE SAISIE ---
input_container = st.container()
vocale_val = st.audio_input("üéôÔ∏è Parler (Micro)", key="micro_input")
texte_val = st.chat_input("Ou √©crire...")

user_final_text = None

if vocale_val:
    with st.spinner("Transcription audio..."):
        text_transcrit = transcrire_audio_user(vocale_val)
        if text_transcrit: user_final_text = text_transcrit
        else: st.warning(f"Je n'ai pas bien entendu. R√©essaie, {titre_user}.")
elif texte_val:
    user_final_text = texte_val

# --- 10. TRAITEMENT & R√âPONSE (AVEC CORRECTIF ANTI-BUG) ---
if user_final_text:
    # 1. Affiche message user tout de suite
    st.chat_message("user").write(user_final_text)
    st.session_state.history.append({"role": "user", "content": user_final_text})
    
    try:
        attendre_creneau_disponible()
        
        # >>> CORRECTIF DU BUG "DICT KEY ERROR" ICI <<<
        # On pr√©pare un historique sp√©cial pour Gemini (format 'parts' au lieu de 'content')
        gemini_history = []
        # On prend tout l'historique SAUF le tout dernier message (qu'on enverra via send_message)
        for msg in st.session_state.history[:-1]:
            role_api = "user" if msg["role"] == "user" else "model"
            gemini_history.append({
                "role": role_api,
                "parts": [msg["content"]]
            })
            
        # On d√©marre la session de chat propre
        chat = model.start_chat(history=gemini_history)
        
        # On envoie le nouveau message
        response = chat.send_message(user_final_text)
        bot_text = response.text
        
        # Affiche r√©ponse IA
        st.chat_message("assistant").write(bot_text)
        st.session_state.history.append({"role": "model", "content": bot_text})
        
        # Audio
        audio_reply = generer_audio_reponse(bot_text)
        if audio_reply: st.audio(audio_reply, format='audio/mp3', start_time=0)
            
    except Exception as e:
        st.error(f"Erreur technique UHG. ({e})")

st.markdown('<div class="footer">UHG-Tech Corp ‚Ä¢ Powered by Franck Ab√© ‚Ä¢ v1.0.3 Fix</div>', unsafe_allow_html=True)

